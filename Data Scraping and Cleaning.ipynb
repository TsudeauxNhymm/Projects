{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I scraped nearly 3000 books from the sixteenth and seventeenth centuries from Early English Books Online.  Some of the centuries did not contain very much text, so I cut those out of my data set.  Cleaning the data set was incredibly simple, as I merely had to get rid of some characters that would show up every once in a while, like the pipeline and slash characters.  I also decided to shift everything to lowercase to cut down on the features that I would be testing over, so now it's mainly spelling and common phrases that I will be looking at.\n",
    "\n",
    "In terms of the reliability of the data, I believe it all to be accurate, given that it was put together by several universities that were tring to make a corpus that was easily searchable and could be used for analysis on  Early Modern English.  I do not foresee any \"hidden agendas\" that might skew the data with which I am concerned.  Similarly, I do not believe there to be values that should concern me besides the occasional illustration or narration tag that shows up in the text.\n",
    "\n",
    "This data set was created specifically for analyses similar to this, and is very suited to it.\n",
    "\n",
    "Below is the code that I used to scrape and clean the data in executable files on one of the lab computers.  I then used the command line to move the files into folders labeled by the publication decade of the books contained therein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as b\n",
    "\n",
    "#try to avoid copyright infringement\n",
    "copyright=re.compile('[pP]rohibit(ed|s)')\n",
    "full_text=re.compile('View entire text')\n",
    "#start off at the beginning browse by title\n",
    "base_url = 'https://quod.lib.umich.edu/e/eebo?cginame=text-idx;id=navbarbrowselink;key=title;page=browse'\n",
    "base_soup = b(requests.get(base_url).text,'html.parser')\n",
    "#navigate to the row of letters\n",
    "first_hierarchy = base_soup.find_all(href=True,class_='browsenav_r1')\n",
    "for i in first_hierarchy[:26]:\n",
    "    #navigate to the row of subletters\n",
    "    next_page = b(requests.get(i.attrs['href']).text,'html.parser')\n",
    "    titlestart=next_page.find_all(href=True,class_='browsenav_r2')\n",
    "    for j,k in enumerate(titlestart):\n",
    "        if j>10:\n",
    "            break\n",
    "        time.sleep(1)\n",
    "        current_page=b(requests.get(k.attrs['href']).text,'html.parser')\n",
    "        #grab the list of browselistitem\n",
    "        \n",
    "        titles = current_page.find_all(class_='browsecell')\n",
    "        for ii,jj in enumerate(titles):\n",
    "            if ii > 20:\n",
    "                break\n",
    "            if ii%2==0:\n",
    "                #alternates between year and link to book\n",
    "                author_year = jj.text\n",
    "            else:\n",
    "                book = b(requests.get(jj.contents[0].attrs['href']).text,'html.parser')\n",
    "                text = []\n",
    "                if book.find(name='p',string=copyright) is not None:  #check the copyright area.\n",
    "                    pass\n",
    "                contents = book.find_all(class_='buttonlink')[-1].contents[0]\n",
    "                time.sleep(1)\n",
    "                page = b(requests.get(contents.attrs['href']).text,'html.parser')\n",
    "                accept = page.find(name='a')\n",
    "                actual = b(requests.get(accept.attrs['href']).text,'html.parser')\n",
    "                for ss in actual.find_all(name='p',limit=4000):\n",
    "                    text.append(ss.string)\n",
    "                #write the text to a file\n",
    "                with open(author_year.replace('.','').replace('/','')+'.txt','a+') as outfile:\n",
    "                    for aa in text:\n",
    "                        if aa is not None:\n",
    "                            outfile.write(aa)\n",
    "                            outfile.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import iglob \n",
    "for i in iglob('*.txt'):\n",
    "    with open(i,'r') as infile:\n",
    "        contents = infile.readlines()\n",
    "    for j in range(len(contents)):\n",
    "        if contents[j] in [' [illustration] ',' [narration]']:  \n",
    "            #there are some of these scattered throughout the data.\n",
    "            contents.remove(contents[j])\n",
    "            pass\n",
    "        contents[j]=contents[j].lower().replace('/','').replace('|','') \n",
    "        #there are some odd characters in the data.\n",
    "        with open(i, 'w') as outfile:\n",
    "            outfile.writelines([j + '\\n' for j in contents])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the data leads me to believe that I will indeed be able to look at the features that I previously intended to use for the purpose of ascertaining the possible presence of words, spellings, and phrases that have a higher frequency in some decades than in others.  This would have ramifications in the world of machine learning and archaeology because it would signify the existence of features to be used in training models to predict how old a document is based on the vocabulary used in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I include a sample of the data after cleaning and scraping.  Note the odd spellings that may be markers of specific eras.\n",
    "\n",
    "\"in the begynnynge and endynge of all good werkes worshyp & thankynge be to almyghty god  maker & byer of all mākynde  begynner and ender of all goodnes  without whose gyfte & helpe no maner vertue is ne may be  whether it be in thought  wyll  or dede  than what euer we synfull creatures thynke or do speke or wryte  that may tourne in to proufyte of mannes soule  to god onely be the worshyp that sente al grace  to vs no praysynge  for of vs without hym cometh no thynge but fylthe & synne. now than good god of his endeles myght & plenteuous goodnes graūte me grace to thynke somwhat of his dere loue & how he sholde be loued  of that same loue some wordes to wryte whiche may to hym be worshyp  to the wryter mede  and proufytable to the reder. amen.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
